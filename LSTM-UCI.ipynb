{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa5bbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68c11f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_UCIHAR(paths):\n",
    "    colnames = ['subject', 'x_acc', 'y_acc', 'z_acc', 'x_gyro', 'y_gyro', 'z_gyro', 'x_total_acc', 'y_total_acc', 'z_total_acc', 'activity']\n",
    "    cols = {col: None for col in colnames}\n",
    "    for i, path in enumerate(paths):\n",
    "        col_data = []\n",
    "        with open(path) as file:\n",
    "            for row in file:\n",
    "                if (i == 0 or i == 10):\n",
    "                    col_data.append(int(row))\n",
    "                else:\n",
    "                    data = re.findall(r'[\\\\+|-]?[1-9]\\.[0-9]+e[+|-][0-9]+', row)\n",
    "                    data_vec = np.array([float(element) for element in data])\n",
    "                    col_data.append(data_vec)\n",
    "        cols[colnames[i]] = col_data\n",
    "    data = pd.DataFrame.from_dict(cols)\n",
    "    return data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19ef8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = ['../Data/UCI HAR Dataset/train/subject_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/body_acc_x_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/body_acc_y_train.txt', \n",
    "                '../Data/UCI HAR Dataset/train/body_acc_z_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/body_gyro_x_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/body_gyro_y_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/body_gyro_z_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/total_acc_x_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/total_acc_y_train.txt', \n",
    "                '../Data/UCI HAR Dataset/train/total_acc_z_train.txt',\n",
    "                '../Data/UCI HAR Dataset/train/y_train.txt'\n",
    "              ]\n",
    "\n",
    "test_paths = ['../Data/UCI HAR Dataset/test/subject_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/body_acc_x_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/body_acc_y_test.txt', \n",
    "                '../Data/UCI HAR Dataset/test/body_acc_z_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/body_gyro_x_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/body_gyro_y_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/body_gyro_z_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/total_acc_x_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/total_acc_y_test.txt', \n",
    "                '../Data/UCI HAR Dataset/test/total_acc_z_test.txt',\n",
    "                '../Data/UCI HAR Dataset/test/y_test.txt'\n",
    "              ]\n",
    "train_data = get_UCIHAR(train_paths)\n",
    "test_data = get_UCIHAR(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e54b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['x_acc', 'y_acc', 'z_acc', 'x_gyro', 'y_gyro', 'z_gyro', 'x_total_acc', 'y_total_acc', 'z_total_acc']\n",
    "def build_features(data):\n",
    "    features = np.empty(shape = (len(data), 9, 128))\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        features[i, :, :] = transfer_column(row)\n",
    "    return features    \n",
    "def transfer_column(row):\n",
    "    transfer_row = np.vstack([row[col] for col in cols])\n",
    "    return transfer_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "748ba9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = build_features(train_data)\n",
    "train_labels = train_data['activity'].to_numpy()\n",
    "train_features_fft = np.abs(np.fft.fft2(train_features))\n",
    "\n",
    "test_features = build_features(test_data)\n",
    "test_labels = test_data['activity'].to_numpy()\n",
    "test_features_fft = np.abs(np.fft.fft2(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95462aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(features, n):\n",
    "    features = np.reshape(features, (n, 128, 9))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84c7383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3be59777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    y = y-1\n",
    "    y = to_categorical(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da138dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = reshape_data(train_features, 7352)\n",
    "test_features = reshape_data(test_features, 2947)\n",
    "train_labels = one_hot(train_labels)\n",
    "test_labels = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29db02a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80c6f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_features, train_labels, test_features, test_labels):\n",
    "    verbose, epochs, batch_size = 0, 15, 64\n",
    "    n_timesteps, n_features, n_outputs = train_features.shape[1], train_features.shape[2], train_labels.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(train_features, train_labels, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    _, accuracy = model.evaluate(test_features, test_labels, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea3f5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise(accuracy_scores):\n",
    "    print(accuracy_scores)\n",
    "    m, s = mean(accuracy_scores), std(accuracy_scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5966e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(train_features, train_labels, test_features, test_labels, repeats=10):\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        accuracy_score = model(train_features, train_labels, test_features, test_labels)\n",
    "        accuracy_score = accuracy_score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, accuracy_score))\n",
    "        scores.append(accuracy_score)\n",
    "    # summarize results\n",
    "    summarise(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28079f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#1: 81.371\n",
      ">#2: 82.457\n",
      ">#3: 80.692\n",
      ">#4: 83.203\n",
      ">#5: 80.930\n",
      ">#6: 83.610\n",
      ">#7: 85.952\n",
      ">#8: 83.950\n",
      ">#9: 82.423\n",
      ">#10: 82.185\n",
      "[81.37088418006897, 82.45673775672913, 80.69223165512085, 83.2032561302185, 80.92975616455078, 83.61045122146606, 85.95181703567505, 83.94978046417236, 82.4228048324585, 82.18527436256409]\n",
      "Accuracy: 82.677% (+/-1.502)\n"
     ]
    }
   ],
   "source": [
    "run_experiment(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba1798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
