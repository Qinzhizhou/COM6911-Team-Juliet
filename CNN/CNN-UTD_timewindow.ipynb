{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eadf10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef362a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_depth_data(action, subject, trial):\n",
    "    filename = f'../Data/UTDMHAD_data/Depth/a{action}_s{subject}_t{trial}_depth.mat'# The name of the .mat files\n",
    "    if Path(filename).is_file():\n",
    "        mat = scipy.io.loadmat(filename)\n",
    "        return mat['d_depth']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def transform_depth_data(action, subject, trial):\n",
    "    rows = []\n",
    "    data = import_depth_data(action, subject, trial)\n",
    "    if data is None: return None\n",
    "    for frame in range(data.shape[2]):\n",
    "        pixels = data[:, :, frame].flatten()\n",
    "        rows.append(pixels)\n",
    "    result = np.insert(rows, 0, [[action], [subject], [trial], [frame]], axis=1)\n",
    "    return np.array(result)\n",
    "\n",
    "def transform_depth_data_to_df(action, subject, trial):\n",
    "    data = transform_depth_data(action, subject, trial)\n",
    "    if data is None: return None\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['action', 'subject', 'trial', 'frame'] + [f'depth_{n}' for n in range(240 * 320)]\n",
    "    return df\n",
    "\n",
    "def export_depth_data_to_csv(action, subject, trial):\n",
    "    df = transform_depth_data_to_df(action, subject, trial)\n",
    "    if df is None: return None\n",
    "    filename = f'a{action}_s{subject}_t{trial}_depth.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def show_depth_image(action, subject, trial, frame):\n",
    "    data = import_depth_data(action, subject, trial)\n",
    "    if data is None: return None\n",
    "    plt.imshow(data[:,:,frame], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c772c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_inertial_data(action, subject, trial):\n",
    "    filename = f'../Data/UTDMHAD_data/Inertial/a{action}_s{subject}_t{trial}_inertial.mat'\n",
    "    if Path(filename).is_file():\n",
    "        mat = scipy.io.loadmat(filename)\n",
    "        return mat['d_iner']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def transform_inertial_data(action, subject, trial):\n",
    "    data = import_inertial_data(action, subject, trial)\n",
    "    if data is None: return None\n",
    "    result = np.insert(data, 0, [[action], [subject], [trial]], axis=1)\n",
    "    return np.array(result)\n",
    "\n",
    "def transform_inertial_data_to_df(action, subject, trial):\n",
    "    data = transform_inertial_data(action, subject, trial)\n",
    "    if data is None: return None\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = ['action', 'subject', 'trial', 'x-accel', 'y-accel', 'z-accel', 'x-ang-accel', 'y-ang-accel', 'z-ang-accel']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d6b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>x-accel</th>\n",
       "      <th>y-accel</th>\n",
       "      <th>z-accel</th>\n",
       "      <th>x-ang-accel</th>\n",
       "      <th>y-ang-accel</th>\n",
       "      <th>z-ang-accel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.959473</td>\n",
       "      <td>-0.177734</td>\n",
       "      <td>-0.192871</td>\n",
       "      <td>5.221374</td>\n",
       "      <td>1.526718</td>\n",
       "      <td>0.152672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.961914</td>\n",
       "      <td>-0.153320</td>\n",
       "      <td>-0.159912</td>\n",
       "      <td>6.778626</td>\n",
       "      <td>1.954198</td>\n",
       "      <td>0.244275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.974609</td>\n",
       "      <td>-0.152832</td>\n",
       "      <td>-0.145996</td>\n",
       "      <td>11.267176</td>\n",
       "      <td>3.175573</td>\n",
       "      <td>1.099237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.941895</td>\n",
       "      <td>-0.135742</td>\n",
       "      <td>-0.127930</td>\n",
       "      <td>16.885496</td>\n",
       "      <td>4.732824</td>\n",
       "      <td>2.320611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.958252</td>\n",
       "      <td>-0.201416</td>\n",
       "      <td>-0.139404</td>\n",
       "      <td>16.030534</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.366412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.908936</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>0.541992</td>\n",
       "      <td>-1.801527</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.909668</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.532471</td>\n",
       "      <td>-2.076336</td>\n",
       "      <td>0.335878</td>\n",
       "      <td>0.244275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.916748</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.528320</td>\n",
       "      <td>-1.954198</td>\n",
       "      <td>0.396947</td>\n",
       "      <td>0.305344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.915039</td>\n",
       "      <td>0.041260</td>\n",
       "      <td>0.534424</td>\n",
       "      <td>-1.648855</td>\n",
       "      <td>0.244275</td>\n",
       "      <td>0.213740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.917236</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>0.539795</td>\n",
       "      <td>-1.862595</td>\n",
       "      <td>0.183206</td>\n",
       "      <td>0.274809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155638 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     action  subject  trial   x-accel   y-accel   z-accel  x-ang-accel  \\\n",
       "0       1.0      1.0    1.0 -0.959473 -0.177734 -0.192871     5.221374   \n",
       "1       1.0      1.0    1.0 -0.961914 -0.153320 -0.159912     6.778626   \n",
       "2       1.0      1.0    1.0 -0.974609 -0.152832 -0.145996    11.267176   \n",
       "3       1.0      1.0    1.0 -0.941895 -0.135742 -0.127930    16.885496   \n",
       "4       1.0      1.0    1.0 -0.958252 -0.201416 -0.139404    16.030534   \n",
       "..      ...      ...    ...       ...       ...       ...          ...   \n",
       "250    27.0      8.0    3.0 -0.908936  0.045410  0.541992    -1.801527   \n",
       "251    27.0      8.0    3.0 -0.909668  0.055176  0.532471    -2.076336   \n",
       "252    27.0      8.0    3.0 -0.916748  0.050781  0.528320    -1.954198   \n",
       "253    27.0      8.0    3.0 -0.915039  0.041260  0.534424    -1.648855   \n",
       "254    27.0      8.0    3.0 -0.917236  0.039307  0.539795    -1.862595   \n",
       "\n",
       "     y-ang-accel  z-ang-accel  \n",
       "0       1.526718     0.152672  \n",
       "1       1.954198     0.244275  \n",
       "2       3.175573     1.099237  \n",
       "3       4.732824     2.320611  \n",
       "4       4.000000     0.366412  \n",
       "..           ...          ...  \n",
       "250     0.427481     0.000000  \n",
       "251     0.335878     0.244275  \n",
       "252     0.396947     0.305344  \n",
       "253     0.244275     0.213740  \n",
       "254     0.183206     0.274809  \n",
       "\n",
       "[155638 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities = [i for i in range(1,28)]\n",
    "raw_dataframe = transform_inertial_data_to_df(0, 0, 0)\n",
    "for index, action in enumerate(activities):\n",
    "    for subject in range(1, 9):\n",
    "        for trial in range(1, 5):\n",
    "            data = transform_inertial_data_to_df(action, subject, trial) # (160, 6)\n",
    "            if data is None: continue\n",
    "            #data = data[0:128] #(128.6) # maximum length is 128\n",
    "            raw_dataframe = pd.concat([raw_dataframe, data])\n",
    "raw_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b20983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size: size of time window\n",
    "# step: overlapping\n",
    "# data: dataset\n",
    "def time_windows(window_size,overlapping,data):\n",
    "  sigmentation_data_temp = []\n",
    "  sigmentation_data = []\n",
    "  sigmentation_label = []\n",
    "  for i in range(0,len(data),overlapping):\n",
    "    acc_x = data['x-accel'].values[i:i+window_size]\n",
    "    acc_y = data['y-accel'].values[i:i+window_size]\n",
    "    acc_z = data['z-accel'].values[i:i+window_size]\n",
    "    gyro_x = data['x-ang-accel'].values[i:i+window_size]\n",
    "    gyro_y = data['y-ang-accel'].values[i:i+window_size]\n",
    "    gyro_z = data['z-ang-accel'].values[i:i+window_size]\n",
    "    total_label = data['action'].values[i:i+window_size]\n",
    "    label = Counter(total_label).most_common()[0][0]\n",
    "    sigmentation_data_temp.append([acc_x,acc_y,acc_z,gyro_x,gyro_y,gyro_z])\n",
    "    sigmentation_arr = np.asarray(sigmentation_data_temp)\n",
    "    sig_size = sigmentation_arr.shape\n",
    "    if sig_size[2] == window_size:\n",
    "      sigmentation_arr.reshape(window_size,6)\n",
    "      sigmentation_data.append(sigmentation_arr)\n",
    "      sigmentation_label.append(label)\n",
    "      sigmentation_data_temp = []\n",
    "    else:\n",
    "      sigmentation_data_temp = []\n",
    "\n",
    "  sigmentation_data_arr = np.asarray(sigmentation_data)\n",
    "  sigmentation_label_arr = np.asarray(sigmentation_label)\n",
    "\n",
    "  return sigmentation_data_arr,sigmentation_label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb160ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "utd_readings,utd_labels = time_windows(128,64,raw_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f8961597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:\n",
      "(2430, 1, 6, 128)\n",
      "Shape of label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2430,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape of data:')\n",
    "print(utd_readings.shape)\n",
    "print('Shape of label')\n",
    "utd_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2902c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "utd_labels -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93d67908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 26., 26., 26.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utd_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ba5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset \n",
    "idx_list = np.array(range(2430))\n",
    "np.random.shuffle(idx_list)\n",
    "train_idxes = idx_list[:2000]\n",
    "test_idxes = idx_list[2000:]\n",
    "train_features = utd_readings[train_idxes]\n",
    "train_labels = utd_labels[train_idxes]\n",
    "test_features = utd_readings[test_idxes]\n",
    "test_labels = utd_labels[test_idxes]\n",
    "# train_features = np.array([utd_readings[i] for i in train_idxes])\n",
    "# train_labels = np.array([utd_labels[i] for i in train_idxes])\n",
    "\n",
    "# test_features = np.array([utd_readings[i] for i in test_idxes])\n",
    "# test_labels = np.array([utd_labels[i] for i in test_idxes])\n",
    "# train_features, train_labels = utd_readings, utd_labels\n",
    "# test_features, test_labels = utd_readings, utd_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed75bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.,  1.,  2., ..., 15., 18., 20.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d8ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_features).to(torch.float32),torch.from_numpy(train_labels).to(torch.float32))\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(test_features).to(torch.float32),torch.from_numpy(test_labels).to(torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f32cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(dataset = train_dataset,batch_size = 64,shuffle = True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset = test_dataset,batch_size = 64,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adcc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e43da715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_UTD(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN_UTD, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2,2))\n",
    "    self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU()\n",
    "    )\n",
    "    # self.drop_out = nn.Dropout()\n",
    "    self.fc1 = nn.Linear(6336, 512)\n",
    "    self.fc3 = nn.Linear(512,27)\n",
    "  def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        # out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "        \n",
    "model = CNN_UTD().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ec51024",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 50\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr, weight_decay=0.0001,momentum = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9db9fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 accuracy:  13.8  % Loss:  2.9845623672008514\n",
      "Epoch:  2 accuracy:  39.0  % Loss:  2.069436427205801\n",
      "Epoch:  3 accuracy:  52.15  % Loss:  1.579998154193163\n",
      "Epoch:  4 accuracy:  61.9  % Loss:  1.1950456574559212\n",
      "Epoch:  5 accuracy:  69.45  % Loss:  0.9560904819518328\n",
      "Epoch:  6 accuracy:  75.75  % Loss:  0.7742084767669439\n",
      "Epoch:  7 accuracy:  79.75  % Loss:  0.6823347173631191\n",
      "Epoch:  8 accuracy:  84.55  % Loss:  0.5271679991856217\n",
      "Epoch:  9 accuracy:  86.45  % Loss:  0.4722176529467106\n",
      "Epoch:  10 accuracy:  88.85  % Loss:  0.3797886432148516\n",
      "Epoch:  11 accuracy:  91.2  % Loss:  0.3123303120955825\n",
      "Epoch:  12 accuracy:  94.7  % Loss:  0.22243187832646072\n",
      "Epoch:  13 accuracy:  93.95  % Loss:  0.20395065331831574\n",
      "Epoch:  14 accuracy:  96.0  % Loss:  0.1511175218038261\n",
      "Epoch:  15 accuracy:  96.8  % Loss:  0.13808455830439925\n",
      "Epoch:  16 accuracy:  96.95  % Loss:  0.12021964020095766\n",
      "Epoch:  17 accuracy:  98.65  % Loss:  0.0883406843058765\n",
      "Epoch:  18 accuracy:  98.65  % Loss:  0.08517759735696018\n",
      "Epoch:  19 accuracy:  97.05  % Loss:  0.11363755317870528\n",
      "Epoch:  20 accuracy:  99.1  % Loss:  0.05203063884982839\n",
      "Epoch:  21 accuracy:  99.6  % Loss:  0.03596304444363341\n",
      "Epoch:  22 accuracy:  99.3  % Loss:  0.04227507975883782\n",
      "Epoch:  23 accuracy:  99.5  % Loss:  0.02929299746756442\n",
      "Epoch:  24 accuracy:  99.7  % Loss:  0.025524028373183683\n",
      "Epoch:  25 accuracy:  99.45  % Loss:  0.02768197156547103\n",
      "Epoch:  26 accuracy:  99.65  % Loss:  0.026367797690909356\n",
      "Epoch:  27 accuracy:  99.4  % Loss:  0.025092540046898648\n",
      "Epoch:  28 accuracy:  99.6  % Loss:  0.021043856177129783\n",
      "Epoch:  29 accuracy:  99.8  % Loss:  0.021016270737163723\n",
      "Epoch:  30 accuracy:  97.8  % Loss:  0.06860563554801047\n",
      "Epoch:  31 accuracy:  98.75  % Loss:  0.05323112217593007\n",
      "Epoch:  32 accuracy:  99.8  % Loss:  0.023298384272493422\n",
      "Epoch:  33 accuracy:  99.85  % Loss:  0.015434903791174293\n",
      "Epoch:  34 accuracy:  99.7  % Loss:  0.017194728381582536\n",
      "Epoch:  35 accuracy:  99.85  % Loss:  0.012476582298404537\n",
      "Epoch:  36 accuracy:  99.85  % Loss:  0.011760110966861248\n",
      "Epoch:  37 accuracy:  99.95  % Loss:  0.01001463711145334\n",
      "Epoch:  38 accuracy:  99.8  % Loss:  0.012002362418570556\n",
      "Epoch:  39 accuracy:  99.5  % Loss:  0.017260710752452724\n",
      "Epoch:  40 accuracy:  99.9  % Loss:  0.008540891743905377\n",
      "Epoch:  41 accuracy:  99.9  % Loss:  0.007815631186531391\n",
      "Epoch:  42 accuracy:  99.9  % Loss:  0.008589415236201603\n",
      "Epoch:  43 accuracy:  99.9  % Loss:  0.008910199234378524\n",
      "Epoch:  44 accuracy:  99.95  % Loss:  0.006393433788616676\n",
      "Epoch:  45 accuracy:  99.9  % Loss:  0.0065130077200592496\n",
      "Epoch:  46 accuracy:  99.9  % Loss:  0.007167780880990904\n",
      "Epoch:  47 accuracy:  99.8  % Loss:  0.010070184551295824\n",
      "Epoch:  48 accuracy:  99.9  % Loss:  0.006064511289878283\n",
      "Epoch:  49 accuracy:  99.95  % Loss:  0.005274345963698579\n",
      "Epoch:  50 accuracy:  100.0  % Loss:  0.004436582399648614\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss_list = []\n",
    "for epoch in range(epoches):\n",
    "    acc = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_num = 0\n",
    "    runtime_loss = 0\n",
    "    for (imgs,labels) in train_loader:\n",
    "        imgs = imgs.reshape(len(imgs),1,32,24)     \n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        runtime_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += labels.size(0)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        loss_num+=1\n",
    "    acc = 100 * correct / total\n",
    "    epoch_loss = runtime_loss / loss_num\n",
    "    loss_list.append(epoch_loss)\n",
    "    loss_num = 0\n",
    "    print(\"Epoch: \",epoch+1, \"accuracy: \", acc,' %',\"Loss: \",epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31bb9bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = []\n",
    "for i in range(1,51):\n",
    "  x.append(i)\n",
    "y = loss_list\n",
    "fig = plt.figure()\n",
    "plt.plot(x,y,color = 'blue')\n",
    "plt.title('training loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a7d592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy is:  65.34883720930233\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct_test = 0\n",
    "\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  for (imgs_test,labels_test) in test_loader:\n",
    "\n",
    "    imgs_test = imgs_test.reshape(len(imgs_test),1,32,24)\n",
    "\n",
    "    imgs_test = imgs_test.to(device)\n",
    "\n",
    "    labels_test = labels_test.type(torch.LongTensor)\n",
    "\n",
    "    labels_test = labels_test.to(device)\n",
    "\n",
    "    outputs_test = model(imgs_test)\n",
    "\n",
    "    labels_test = labels_test.reshape(labels_test.shape[0],)\n",
    "\n",
    "    predicted_test = torch.max(outputs_test.data,1)[1]\n",
    "      \n",
    "    total_test += labels_test.size(0)\n",
    "      \n",
    "    correct_test += (predicted_test == labels_test).sum().item()\n",
    "\n",
    "    test_accuracy = 100*correct_test/total_test\n",
    "\n",
    "print('validation accuracy is: ',test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
