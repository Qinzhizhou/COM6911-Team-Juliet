{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-USCHAD_w128_o50.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DKzFpxZ30ENj",
        "GdLgtk323ZPY",
        "COF7G4be7PO6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLc5jd6wOgXo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data\n",
        "usc_raw_data = pd.read_csv('/content/drive/MyDrive/Industrial Team Project/USCHAD_rawdata.csv')"
      ],
      "metadata": {
        "id": "lWJtcBhZPI-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only features and label.\n",
        "usc_unprocessed = usc_raw_data[['acc_x','acc_y','acc_z','gyro_x','gyro_y','gyro_z','label']]"
      ],
      "metadata": {
        "id": "JgLIOSDNeDvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usc_unprocessed.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SjrOukIQtDdt",
        "outputId": "39f09b29-7707-48eb-8d6d-ee22c299c296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  label\n",
              "0  0.977355  0.125578 -0.072511 -1.934198  4.831090 -3.059582      7\n",
              "1  0.980789  0.125578 -0.072511 -1.128533  4.806113 -2.639555      7\n",
              "2  0.980789  0.121959 -0.068851 -1.128533  3.979873 -2.222339      7\n",
              "3  0.980789  0.121959 -0.072511 -0.725701  2.757195 -3.008654      7\n",
              "4  0.980789  0.121959 -0.068851 -1.118572  2.743157 -2.989551      7"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b172433-4eba-4601-b377-5670ef1818e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc_x</th>\n",
              "      <th>acc_y</th>\n",
              "      <th>acc_z</th>\n",
              "      <th>gyro_x</th>\n",
              "      <th>gyro_y</th>\n",
              "      <th>gyro_z</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.977355</td>\n",
              "      <td>0.125578</td>\n",
              "      <td>-0.072511</td>\n",
              "      <td>-1.934198</td>\n",
              "      <td>4.831090</td>\n",
              "      <td>-3.059582</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.980789</td>\n",
              "      <td>0.125578</td>\n",
              "      <td>-0.072511</td>\n",
              "      <td>-1.128533</td>\n",
              "      <td>4.806113</td>\n",
              "      <td>-2.639555</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.980789</td>\n",
              "      <td>0.121959</td>\n",
              "      <td>-0.068851</td>\n",
              "      <td>-1.128533</td>\n",
              "      <td>3.979873</td>\n",
              "      <td>-2.222339</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.980789</td>\n",
              "      <td>0.121959</td>\n",
              "      <td>-0.072511</td>\n",
              "      <td>-0.725701</td>\n",
              "      <td>2.757195</td>\n",
              "      <td>-3.008654</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.980789</td>\n",
              "      <td>0.121959</td>\n",
              "      <td>-0.068851</td>\n",
              "      <td>-1.118572</td>\n",
              "      <td>2.743157</td>\n",
              "      <td>-2.989551</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b172433-4eba-4601-b377-5670ef1818e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b172433-4eba-4601-b377-5670ef1818e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b172433-4eba-4601-b377-5670ef1818e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# window_size: size of time window\n",
        "# step: overlapping\n",
        "# data: dataset\n",
        "def time_windows(window_size,overlapping,data):\n",
        "  sigmentation_data_temp = []\n",
        "  sigmentation_data = []\n",
        "  sigmentation_label = []\n",
        "  for i in range(0,len(data),overlapping):\n",
        "    acc_x = data['acc_x'].values[i:i+window_size]\n",
        "    acc_y = data['acc_y'].values[i:i+window_size]\n",
        "    acc_z = data['acc_z'].values[i:i+window_size]\n",
        "    gyro_x = data['gyro_x'].values[i:i+window_size]\n",
        "    gyro_y = data['gyro_y'].values[i:i+window_size]\n",
        "    gyro_z = data['gyro_z'].values[i:i+window_size]\n",
        "    total_label = data['label'].values[i:i+window_size]\n",
        "    label = Counter(total_label).most_common()[0][0]\n",
        "    sigmentation_data_temp.append([acc_x,acc_y,acc_z,gyro_x,gyro_y,gyro_z])\n",
        "    sigmentation_arr = np.asarray(sigmentation_data_temp)\n",
        "    sig_size = sigmentation_arr.shape\n",
        "    if sig_size[2] == window_size:\n",
        "      sigmentation_arr.reshape(window_size,6)\n",
        "      sigmentation_data.append(sigmentation_arr)\n",
        "      sigmentation_label.append(label)\n",
        "      sigmentation_data_temp = []\n",
        "    else:\n",
        "      sigmentation_data_temp = []\n",
        "\n",
        "  sigmentation_data_arr = np.asarray(sigmentation_data)\n",
        "  sigmentation_label_arr = np.asarray(sigmentation_label)\n",
        "\n",
        "  return sigmentation_data_arr,sigmentation_label_arr\n"
      ],
      "metadata": {
        "id": "9XLG4Gn-tKpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here use semi-non-overlapping\n",
        "# signal segmentation and relevant labels\n",
        "uci_readings,uci_labels = time_windows(128,64,usc_unprocessed)"
      ],
      "metadata": {
        "id": "zN-E84m783wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in the model, requires 0-n label so make labels from 1-12 into 0-11\n",
        "uci_labels = uci_labels-1"
      ],
      "metadata": {
        "id": "Q3bxbiAELH1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of data:')\n",
        "print(uci_readings.shape)\n",
        "print('#######################')\n",
        "print('Shape of labels: ')\n",
        "print(uci_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82KEQT9kJr56",
        "outputId": "f67fc849-7ac9-4245-8250-a27a6e53bebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data:\n",
            "(43894, 1, 6, 128)\n",
            "#######################\n",
            "Shape of labels: \n",
            "(43894,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use train_test_split to generate train,val and test data\n",
        "x_train,x_val_test,y_train,y_val_test = train_test_split(uci_readings,uci_labels,test_size = 0.3)\n",
        "x_val,x_test,y_val,y_test = train_test_split(x_val_test,y_val_test,test_size = 0.3 )"
      ],
      "metadata": {
        "id": "bZE8XWM6KXPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use torch.TensorDataset to make dataset\n",
        "train_dataset = TensorDataset(torch.from_numpy(x_train).to(torch.float32),torch.from_numpy(y_train).to(torch.float32))\n",
        "val_dataset = TensorDataset(torch.from_numpy(x_val).to(torch.float32),torch.from_numpy(y_val).to(torch.float32))\n",
        "test_dataset = TensorDataset(torch.from_numpy(x_test).to(torch.float32),torch.from_numpy(y_test).to(torch.float32))"
      ],
      "metadata": {
        "id": "QT92qKzqRf6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader generation\n",
        "train_loader = data.DataLoader(dataset = train_dataset,batch_size = 64,shuffle = True)\n",
        "val_loader = data.DataLoader(dataset = val_dataset,batch_size = 64,shuffle = True)\n",
        "test_loader = data.DataLoader(dataset = test_dataset,batch_size = 64,shuffle = False)"
      ],
      "metadata": {
        "id": "pX7NAsa2UJtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 50% overlapping"
      ],
      "metadata": {
        "id": "yPzKixfC60TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # now define a class of CNN model\n",
        "class CNN_50(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_50, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2,2))\n",
        "    self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU()\n",
        "    )\n",
        "    # self.drop_out = nn.Dropout()\n",
        "    self.fc1 = nn.Linear(3072, 512)\n",
        "    self.fc3 = nn.Linear(512,12)\n",
        "  def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        # out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "        \n",
        "model_50 = CNN_50().to(device)"
      ],
      "metadata": {
        "id": "27kecFzjYRhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "epoches = 50\n",
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_50.parameters(),lr=lr, weight_decay=0.0001,momentum = 0.8)"
      ],
      "metadata": {
        "id": "gCE2BvFYZ2LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "loss_list = []\n",
        "for epoch in range(epoches):\n",
        "    acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_num = 0\n",
        "    runtime_loss = 0\n",
        "    for (imgs,labels) in train_loader:\n",
        "        imgs = imgs.reshape(len(imgs),1,32,24)     \n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_50(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        runtime_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss_num+=1\n",
        "    acc = 100 * correct / total\n",
        "    epoch_loss = runtime_loss / loss_num\n",
        "    loss_list.append(epoch_loss)\n",
        "    loss_num = 0\n",
        "    print(\"Epoch: \",epoch+1, \"accuracy: \", acc,' %',\"Loss: \",epoch_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHKyoAymZ9yW",
        "outputId": "5904b1f4-71f3-4cbe-8863-a46f84e2d02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 accuracy:  49.3246541903987  % Loss:  1.4272949007841258\n",
            "Epoch:  2 accuracy:  63.44344995931652  % Loss:  1.0286866220763715\n",
            "Epoch:  3 accuracy:  69.71847030105776  % Loss:  0.8498693025533474\n",
            "Epoch:  4 accuracy:  76.40358014646054  % Loss:  0.6725571656177545\n",
            "Epoch:  5 accuracy:  80.33523189585028  % Loss:  0.5431646777165903\n",
            "Epoch:  6 accuracy:  81.89096826688365  % Loss:  0.4929561317896397\n",
            "Epoch:  7 accuracy:  82.64605370219691  % Loss:  0.4649370574467891\n",
            "Epoch:  8 accuracy:  83.32628152969895  % Loss:  0.44421599204351897\n",
            "Epoch:  9 accuracy:  83.38161106590724  % Loss:  0.43703675867985786\n",
            "Epoch:  10 accuracy:  83.9446704637917  % Loss:  0.4133855026532855\n",
            "Epoch:  11 accuracy:  84.68348250610252  % Loss:  0.3976733262908186\n",
            "Epoch:  12 accuracy:  84.92432872253865  % Loss:  0.38875234474015585\n",
            "Epoch:  13 accuracy:  85.23677786818551  % Loss:  0.37542441087676187\n",
            "Epoch:  14 accuracy:  85.73148901545973  % Loss:  0.36316662868814015\n",
            "Epoch:  15 accuracy:  85.97233523189585  % Loss:  0.35329839969034504\n",
            "Epoch:  16 accuracy:  86.4279902359642  % Loss:  0.34730969254787153\n",
            "Epoch:  17 accuracy:  86.47355573637104  % Loss:  0.33911321958112617\n",
            "Epoch:  18 accuracy:  86.68185516680228  % Loss:  0.3338224030953683\n",
            "Epoch:  19 accuracy:  87.11798209926769  % Loss:  0.33339024325852085\n",
            "Epoch:  20 accuracy:  86.73718470301058  % Loss:  0.3325686010061579\n",
            "Epoch:  21 accuracy:  87.64849471114728  % Loss:  0.30759175411442957\n",
            "Epoch:  22 accuracy:  87.60943856794141  % Loss:  0.3033125304661521\n",
            "Epoch:  23 accuracy:  88.10414971521563  % Loss:  0.29262947840248227\n",
            "Epoch:  24 accuracy:  88.34174125305127  % Loss:  0.2870574103292705\n",
            "Epoch:  25 accuracy:  88.59886086248983  % Loss:  0.2831659794101596\n",
            "Epoch:  26 accuracy:  88.55980471928397  % Loss:  0.28029520303522104\n",
            "Epoch:  27 accuracy:  88.89178193653376  % Loss:  0.2718393681203006\n",
            "Epoch:  28 accuracy:  88.84947111472742  % Loss:  0.27012032471798564\n",
            "Epoch:  29 accuracy:  88.70951993490642  % Loss:  0.26914217656094913\n",
            "Epoch:  30 accuracy:  89.29861676159479  % Loss:  0.25706647486733797\n",
            "Epoch:  31 accuracy:  89.31163547599675  % Loss:  0.25653440729867893\n",
            "Epoch:  32 accuracy:  89.51017087062652  % Loss:  0.2502097021827083\n",
            "Epoch:  33 accuracy:  89.75101708706265  % Loss:  0.2483836603418705\n",
            "Epoch:  34 accuracy:  87.68755085435313  % Loss:  0.3039716649142224\n",
            "Epoch:  35 accuracy:  89.30838079739625  % Loss:  0.25467307004388307\n",
            "Epoch:  36 accuracy:  89.379983726607  % Loss:  0.2462228024746301\n",
            "Epoch:  37 accuracy:  89.82912937347437  % Loss:  0.2384296059918255\n",
            "Epoch:  38 accuracy:  90.23921887713588  % Loss:  0.23289069853986374\n",
            "Epoch:  39 accuracy:  90.14808787632221  % Loss:  0.22954022238445382\n",
            "Epoch:  40 accuracy:  90.34987794955248  % Loss:  0.22394316943978074\n",
            "Epoch:  41 accuracy:  90.35313262815296  % Loss:  0.22414119653171413\n",
            "Epoch:  42 accuracy:  90.58746948738812  % Loss:  0.21835884307811265\n",
            "Epoch:  43 accuracy:  90.56143205858422  % Loss:  0.22014176133021\n",
            "Epoch:  44 accuracy:  90.45728234336859  % Loss:  0.22232759599874025\n",
            "Epoch:  45 accuracy:  90.19365337672905  % Loss:  0.2372484242779797\n",
            "Epoch:  46 accuracy:  90.65581773799838  % Loss:  0.21472687209741428\n",
            "Epoch:  47 accuracy:  90.85435313262815  % Loss:  0.20582044945561218\n",
            "Epoch:  48 accuracy:  90.99755899104963  % Loss:  0.20638603470026828\n",
            "Epoch:  49 accuracy:  91.30675345809601  % Loss:  0.19930422876084422\n",
            "Epoch:  50 accuracy:  91.23515052888527  % Loss:  0.1986029173892278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = []\n",
        "for i in range(1,51):\n",
        "  x.append(i)\n",
        "y = loss_list\n",
        "fig = plt.figure()\n",
        "plt.plot(x,y,color = 'blue')\n",
        "plt.title('training loss history')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t5IpD6ueY_V3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "09b4c89e-6054-4bf4-910c-9bbedeb157bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "correct_test = 0\n",
        "\n",
        "total_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for (imgs_test,labels_test) in test_loader:\n",
        "\n",
        "    imgs_test = imgs_test.reshape(len(imgs_test),1,32,24)\n",
        "\n",
        "    imgs_test = imgs_test.to(device)\n",
        "\n",
        "    labels_test = labels_test.type(torch.LongTensor)\n",
        "\n",
        "    labels_test = labels_test.to(device)\n",
        "\n",
        "    outputs_test = model_50(imgs_test)\n",
        "\n",
        "    labels_test = labels_test.reshape(labels_test.shape[0],)\n",
        "\n",
        "    predicted_test = torch.max(outputs_test.data,1)[1]\n",
        "      \n",
        "    total_test += labels_test.size(0)\n",
        "      \n",
        "    correct_test += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    test_accuracy = 100*correct_test/total_test\n",
        "\n",
        "print('Test accuracy is: ',test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsAsxUVU9pAU",
        "outputId": "308b5b60-fae2-48b4-91ba-2f929091bcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is:  86.45912427233611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0 overlapping\n",
        "\n",
        "2layers 3x3 : 73% |||\n",
        "2layers 5x5 : 74.9% |||\n",
        "3layers 3x3 : 83.5 |||\n",
        "3layers 5x5 : 85.1 |||\n",
        "\n",
        "final decision : 3layers 5x5\n"
      ],
      "metadata": {
        "id": "DKzFpxZ30ENj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2layers"
      ],
      "metadata": {
        "id": "GdLgtk323ZPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uci_readings_non_overlapping,uci_labels_non_overlapping = time_windows(128,128,usc_unprocessed)"
      ],
      "metadata": {
        "id": "0_r1koUp0SaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uci_labels_non_overlapping = uci_labels_non_overlapping - 1"
      ],
      "metadata": {
        "id": "MdwD7hyX1GQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_non_overlapping,x_val_test_non_overlapping,y_train_non_overlapping,y_val_test_non_overlapping = train_test_split(uci_readings_non_overlapping,uci_labels_non_overlapping,test_size = 0.3)\n",
        "x_val_non_overlapping,x_test_non_overlapping,y_val_non_overlapping,y_test_non_overlapping = train_test_split(x_val_test_non_overlapping,y_val_test_non_overlapping,test_size = 0.3 )"
      ],
      "metadata": {
        "id": "PVGdWVfM1LeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_non_overlapping = TensorDataset(torch.from_numpy(x_train_non_overlapping).to(torch.float32),torch.from_numpy(y_train_non_overlapping).to(torch.float32))\n",
        "val_dataset_non_overlapping = TensorDataset(torch.from_numpy(x_val_non_overlapping).to(torch.float32),torch.from_numpy(y_val_non_overlapping).to(torch.float32))\n",
        "test_dataset_non_overlapping = TensorDataset(torch.from_numpy(x_test_non_overlapping).to(torch.float32),torch.from_numpy(y_test_non_overlapping).to(torch.float32))"
      ],
      "metadata": {
        "id": "B4iw-1Ot1ntG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader generation\n",
        "train_loader_non_overlapping = data.DataLoader(dataset = train_dataset_non_overlapping,batch_size = 64,shuffle = True)\n",
        "val_loader_non_overlapping = data.DataLoader(dataset = val_dataset_non_overlapping,batch_size = 64,shuffle = True)\n",
        "test_loader_non_overlapping = data.DataLoader(dataset = test_dataset_non_overlapping,batch_size = 64,shuffle = False)"
      ],
      "metadata": {
        "id": "4k3B-noT1qXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # now define a class of CNN model\n",
        "class CNN_non_overlapping_2layers(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_non_overlapping_2layers, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    # self.layer2 = nn.Sequential(\n",
        "    #         nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2),\n",
        "    #         nn.ReLU(),\n",
        "    #         nn.BatchNorm2d(32),\n",
        "    #         nn.MaxPool2d(2,2))\n",
        "    self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU()\n",
        "    )\n",
        "    # self.drop_out = nn.Dropout()\n",
        "    self.fc1 = nn.Linear(12288, 512)\n",
        "    self.fc3 = nn.Linear(512,12)\n",
        "  def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        # out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        # out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "        \n",
        "model_non_overlapping_2layers = CNN_non_overlapping_2layers().to(device)"
      ],
      "metadata": {
        "id": "51NAe6Hg2DMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoches = 50\n",
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_non_overlapping_2layers.parameters(),lr=lr, weight_decay=0.0001,momentum = 0.8)"
      ],
      "metadata": {
        "id": "SS5S_6pL2tui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "loss_list = []\n",
        "for epoch in range(epoches):\n",
        "    acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_num = 0\n",
        "    runtime_loss = 0\n",
        "    for (imgs,labels) in train_loader_non_overlapping:\n",
        "        imgs = imgs.reshape(len(imgs),1,32,24)     \n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_non_overlapping_2layers(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        runtime_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss_num+=1\n",
        "    acc = 100 * correct / total\n",
        "    epoch_loss = runtime_loss / loss_num\n",
        "    loss_list.append(epoch_loss)\n",
        "    loss_num = 0\n",
        "    print(\"Epoch: \",epoch+1, \"accuracy: \", acc,' %',\"Loss: \",epoch_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB4c7r6j2dDA",
        "outputId": "d241adbf-58d6-4fc0-b858-adc428207883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 accuracy:  44.49290456971748  % Loss:  1.532622358611016\n",
            "Epoch:  2 accuracy:  55.46152844681682  % Loss:  1.2222759787967097\n",
            "Epoch:  3 accuracy:  59.35425074860044  % Loss:  1.1497134464904974\n",
            "Epoch:  4 accuracy:  63.14281994531962  % Loss:  1.0748642057304065\n",
            "Epoch:  5 accuracy:  65.39513084233823  % Loss:  1.0042939665901216\n",
            "Epoch:  6 accuracy:  67.26337716443172  % Loss:  0.9441210165063375\n",
            "Epoch:  7 accuracy:  69.16417133185783  % Loss:  0.8760925682253857\n",
            "Epoch:  8 accuracy:  71.46204921234214  % Loss:  0.8120593271562173\n",
            "Epoch:  9 accuracy:  73.91615675042313  % Loss:  0.750220776840859\n",
            "Epoch:  10 accuracy:  76.07733368051035  % Loss:  0.6994513294261521\n",
            "Epoch:  11 accuracy:  77.95859914073688  % Loss:  0.6439038765659223\n",
            "Epoch:  12 accuracy:  79.38419476630646  % Loss:  0.6052083572164116\n",
            "Epoch:  13 accuracy:  79.5534435620362  % Loss:  0.5908498487037247\n",
            "Epoch:  14 accuracy:  81.31753677906522  % Loss:  0.5494866228944533\n",
            "Epoch:  15 accuracy:  81.61046738705897  % Loss:  0.5162513139676999\n",
            "Epoch:  16 accuracy:  82.19632860304648  % Loss:  0.5037250651116193\n",
            "Epoch:  17 accuracy:  82.15076161958078  % Loss:  0.49833984660657116\n",
            "Epoch:  18 accuracy:  82.47624007290717  % Loss:  0.4921947488275306\n",
            "Epoch:  19 accuracy:  82.50878791823982  % Loss:  0.482487780857383\n",
            "Epoch:  20 accuracy:  83.49824241635204  % Loss:  0.4498037693411483\n",
            "Epoch:  21 accuracy:  83.45267543288634  % Loss:  0.4509905495089614\n",
            "Epoch:  22 accuracy:  84.32495768780107  % Loss:  0.43076179253857166\n",
            "Epoch:  23 accuracy:  84.23382372086968  % Loss:  0.42867224246139846\n",
            "Epoch:  24 accuracy:  84.31193854966801  % Loss:  0.42148608519575903\n",
            "Epoch:  25 accuracy:  84.72855096992579  % Loss:  0.4042400383850351\n",
            "Epoch:  26 accuracy:  85.33394089311288  % Loss:  0.40669047263648006\n",
            "Epoch:  27 accuracy:  82.54784533263899  % Loss:  0.5461953458573313\n",
            "Epoch:  28 accuracy:  83.77815388621273  % Loss:  0.4494459668630386\n",
            "Epoch:  29 accuracy:  84.09061320140607  % Loss:  0.41487314518061913\n",
            "Epoch:  30 accuracy:  85.12563468298399  % Loss:  0.3961652619339124\n",
            "Epoch:  31 accuracy:  85.73102460617108  % Loss:  0.3843782651721195\n",
            "Epoch:  32 accuracy:  85.41205572191122  % Loss:  0.3980266430194942\n",
            "Epoch:  33 accuracy:  86.05650305949746  % Loss:  0.38086406651621535\n",
            "Epoch:  34 accuracy:  82.86681421689885  % Loss:  0.482238552135056\n",
            "Epoch:  35 accuracy:  85.11261554485093  % Loss:  0.38885766051369586\n",
            "Epoch:  36 accuracy:  85.82215857310246  % Loss:  0.3621395423513725\n",
            "Epoch:  37 accuracy:  86.30386668402552  % Loss:  0.3466132750340517\n",
            "Epoch:  38 accuracy:  86.64887384455149  % Loss:  0.335929148316507\n",
            "Epoch:  39 accuracy:  87.01991928134358  % Loss:  0.3330313434121025\n",
            "Epoch:  40 accuracy:  86.3689623746908  % Loss:  0.3392116513984332\n",
            "Epoch:  41 accuracy:  87.26728290587162  % Loss:  0.31648095633788226\n",
            "Epoch:  42 accuracy:  87.61879963546413  % Loss:  0.3169783314852299\n",
            "Epoch:  43 accuracy:  87.31284988933733  % Loss:  0.3141473809110302\n",
            "Epoch:  44 accuracy:  87.66436661892983  % Loss:  0.30662141151192956\n",
            "Epoch:  45 accuracy:  88.15909386798594  % Loss:  0.29884759179042086\n",
            "Epoch:  46 accuracy:  88.34136180184872  % Loss:  0.2962656470562217\n",
            "Epoch:  47 accuracy:  88.28277568024997  % Loss:  0.2907633959505073\n",
            "Epoch:  48 accuracy:  88.62778284077594  % Loss:  0.28556001945521925\n",
            "Epoch:  49 accuracy:  88.7840124983726  % Loss:  0.28180190288612456\n",
            "Epoch:  50 accuracy:  88.36740007811483  % Loss:  0.2885311819705726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "correct_test = 0\n",
        "\n",
        "total_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for (imgs_test,labels_test) in test_loader_non_overlapping:\n",
        "\n",
        "    imgs_test = imgs_test.reshape(len(imgs_test),1,32,24)\n",
        "\n",
        "    imgs_test = imgs_test.to(device)\n",
        "\n",
        "    labels_test = labels_test.type(torch.LongTensor)\n",
        "\n",
        "    labels_test = labels_test.to(device)\n",
        "\n",
        "    outputs_test = model_non_overlapping_2layers(imgs_test)\n",
        "\n",
        "    labels_test = labels_test.reshape(labels_test.shape[0],)\n",
        "\n",
        "    predicted_test = torch.max(outputs_test.data,1)[1]\n",
        "      \n",
        "    total_test += labels_test.size(0)\n",
        "      \n",
        "    correct_test += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    test_accuracy = 100*correct_test/total_test\n",
        "\n",
        "print('Test accuracy is: ',test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee1edwQw2X4y",
        "outputId": "6f48ca2b-3dd8-4eb3-ece3-484741a4f01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is:  74.9493927125506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3layers"
      ],
      "metadata": {
        "id": "3UxdrNTP3gdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Layers(not expected, marked)"
      ],
      "metadata": {
        "id": "COF7G4be7PO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # now define a class of CNN model\n",
        "class CNN_non_overlapping_4layers(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_non_overlapping_4layers, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "             nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "             nn.ReLU(),\n",
        "             nn.BatchNorm2d(32),\n",
        "             nn.MaxPool2d(2,2))\n",
        "    self.layer3 = nn.Sequential(\n",
        "             nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "             nn.ReLU(),\n",
        "             nn.BatchNorm2d(64),\n",
        "             nn.MaxPool2d(2,2))\n",
        "    self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU()\n",
        "    )\n",
        "    self.drop_out = nn.Dropout()\n",
        "    self.fc1 = nn.Linear(1536, 512)\n",
        "    self.fc3 = nn.Linear(512,12)\n",
        "  def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "        \n",
        "model_non_overlapping_4layers = CNN_non_overlapping_4layers().to(device)"
      ],
      "metadata": {
        "id": "6k4CrY_m7XwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoches = 50\n",
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_non_overlapping_4layers.parameters(),lr=lr, weight_decay=0.0001,momentum = 0.8)"
      ],
      "metadata": {
        "id": "Z_FAO21F7slz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "loss_list = []\n",
        "for epoch in range(epoches):\n",
        "    acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_num = 0\n",
        "    runtime_loss = 0\n",
        "    for (imgs,labels) in train_loader_non_overlapping:\n",
        "        imgs = imgs.reshape(len(imgs),1,32,24)     \n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_non_overlapping_4layers(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        runtime_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data,1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        loss_num+=1\n",
        "    acc = 100 * correct / total\n",
        "    epoch_loss = runtime_loss / loss_num\n",
        "    loss_list.append(epoch_loss)\n",
        "    loss_num = 0\n",
        "    print(\"Epoch: \",epoch+1, \"accuracy: \", acc,' %',\"Loss: \",epoch_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC1MCl127uMq",
        "outputId": "e4546052-fa14-48a0-d522-be506948367d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 accuracy:  39.35685457622705  % Loss:  1.7711191053707076\n",
            "Epoch:  2 accuracy:  52.92279651087098  % Loss:  1.258254825821556\n",
            "Epoch:  3 accuracy:  61.150891810962115  % Loss:  1.0869571675403484\n",
            "Epoch:  4 accuracy:  67.95990105455019  % Loss:  0.9131546539884385\n",
            "Epoch:  5 accuracy:  75.08787918239813  % Loss:  0.7195416513320322\n",
            "Epoch:  6 accuracy:  77.8218981903398  % Loss:  0.6305727336663923\n",
            "Epoch:  7 accuracy:  79.37117562817342  % Loss:  0.5635268778474499\n",
            "Epoch:  8 accuracy:  80.92696263507356  % Loss:  0.5099657576732121\n",
            "Epoch:  9 accuracy:  81.96198411665148  % Loss:  0.48496404216002625\n",
            "Epoch:  10 accuracy:  82.87332378596537  % Loss:  0.4620056444183919\n",
            "Epoch:  11 accuracy:  83.74560604088009  % Loss:  0.42970076945312785\n",
            "Epoch:  12 accuracy:  83.95391225100899  % Loss:  0.4124357416545702\n",
            "Epoch:  13 accuracy:  84.36401510220024  % Loss:  0.4001222814189819\n",
            "Epoch:  14 accuracy:  84.93685718005469  % Loss:  0.381699328105974\n",
            "Epoch:  15 accuracy:  85.27535477151413  % Loss:  0.3714764958471678\n",
            "Epoch:  16 accuracy:  85.44460356724385  % Loss:  0.38013976830911833\n",
            "Epoch:  17 accuracy:  85.69196719177191  % Loss:  0.3565227874009812\n",
            "Epoch:  18 accuracy:  86.64887384455149  % Loss:  0.33096107741609154\n",
            "Epoch:  19 accuracy:  85.47715141257649  % Loss:  0.36028328921290353\n",
            "Epoch:  20 accuracy:  84.93685718005469  % Loss:  0.3746294733523333\n",
            "Epoch:  21 accuracy:  87.08501497200885  % Loss:  0.31811106619251217\n",
            "Epoch:  22 accuracy:  87.32586902747038  % Loss:  0.3085572539028785\n",
            "Epoch:  23 accuracy:  86.84416091654732  % Loss:  0.3206166021556775\n",
            "Epoch:  24 accuracy:  88.30881395651608  % Loss:  0.2842081064682964\n",
            "Epoch:  25 accuracy:  87.95078765785705  % Loss:  0.2870601730351626\n",
            "Epoch:  26 accuracy:  88.21117042051816  % Loss:  0.2809749709449987\n",
            "Epoch:  27 accuracy:  88.7579742221065  % Loss:  0.26039626168017566\n",
            "Epoch:  28 accuracy:  89.21364405676344  % Loss:  0.2605728909249622\n",
            "Epoch:  29 accuracy:  83.74560604088009  % Loss:  0.42282066552965475\n",
            "Epoch:  30 accuracy:  85.01497200885301  % Loss:  0.3908579339624935\n",
            "Epoch:  31 accuracy:  86.56424944668663  % Loss:  0.3274000355224144\n",
            "Epoch:  32 accuracy:  88.11352688452024  % Loss:  0.28107660548197283\n",
            "Epoch:  33 accuracy:  86.3950006509569  % Loss:  0.32579592500979476\n",
            "Epoch:  34 accuracy:  89.16156750423121  % Loss:  0.2610212972240824\n",
            "Epoch:  35 accuracy:  86.85067048561385  % Loss:  0.31862817760325074\n",
            "Epoch:  36 accuracy:  89.15505793516469  % Loss:  0.2551007136911216\n",
            "Epoch:  37 accuracy:  89.64327561515428  % Loss:  0.23922352891616308\n",
            "Epoch:  38 accuracy:  87.07850540294233  % Loss:  0.3152122264302865\n",
            "Epoch:  39 accuracy:  89.24619190209609  % Loss:  0.2456009840318369\n",
            "Epoch:  40 accuracy:  89.79299570368441  % Loss:  0.23454883351489222\n",
            "Epoch:  41 accuracy:  89.85158182528316  % Loss:  0.2621297898752561\n",
            "Epoch:  42 accuracy:  88.12003645358678  % Loss:  0.27830375602692986\n",
            "Epoch:  43 accuracy:  90.02734019007941  % Loss:  0.22473956685352886\n",
            "Epoch:  44 accuracy:  90.40489519593802  % Loss:  0.2186867860203833\n",
            "Epoch:  45 accuracy:  90.75641192553053  % Loss:  0.20924562738273153\n",
            "Epoch:  46 accuracy:  90.6782970967322  % Loss:  0.22641619446366654\n",
            "Epoch:  47 accuracy:  86.90274703814607  % Loss:  0.30887495206970395\n",
            "Epoch:  48 accuracy:  89.78648613461789  % Loss:  0.23112461267665213\n",
            "Epoch:  49 accuracy:  86.33641452935815  % Loss:  0.33229463717502183\n",
            "Epoch:  50 accuracy:  89.2722301783622  % Loss:  0.2494723499439564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "correct_test = 0\n",
        "\n",
        "total_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for (imgs_test,labels_test) in test_loader_non_overlapping:\n",
        "\n",
        "    imgs_test = imgs_test.reshape(len(imgs_test),1,32,24)\n",
        "\n",
        "    imgs_test = imgs_test.to(device)\n",
        "\n",
        "    labels_test = labels_test.type(torch.LongTensor)\n",
        "\n",
        "    labels_test = labels_test.to(device)\n",
        "\n",
        "    outputs_test = model_non_overlapping_4layers(imgs_test)\n",
        "\n",
        "    labels_test = labels_test.reshape(labels_test.shape[0],)\n",
        "\n",
        "    predicted_test = torch.max(outputs_test.data,1)[1]\n",
        "      \n",
        "    total_test += labels_test.size(0)\n",
        "      \n",
        "    correct_test += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    test_accuracy = 100*correct_test/total_test\n",
        "\n",
        "print('Test accuracy is: ',test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMN4re4F72YK",
        "outputId": "731a8d12-ef85-4874-df28-765af7925e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is:  82.99595141700405\n"
          ]
        }
      ]
    }
  ]
}